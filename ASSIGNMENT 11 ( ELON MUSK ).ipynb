{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "303b6ed1",
   "metadata": {},
   "source": [
    "1) Perform sentimental analysis on the Elon-musk tweets (Exlon-musk.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0436d045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27839944",
   "metadata": {},
   "outputs": [],
   "source": [
    "elon = pd.read_csv(\"/Users/nihadnazar/Desktop/ASSIGNMENTS/DATASETS/Elon_musk.csv\",encoding=\"latin 1\")\n",
    "elon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98305be",
   "metadata": {},
   "outputs": [],
   "source": [
    "elon.iloc[:,1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5f8fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "elon.drop(['Unnamed: 0'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cdd070",
   "metadata": {},
   "outputs": [],
   "source": [
    "elon.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f29983b",
   "metadata": {},
   "source": [
    "TEXT PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea94dcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "def clean_Text(Text):\n",
    "    Text = Text.lower()\n",
    "    Text = re.sub('\\[.*?\\]', '', Text)\n",
    "    Text = re.sub('[%s]' % re.escape(string.punctuation), '', Text)\n",
    "    Text = re.sub('\\w*\\d\\w*', '', Text)\n",
    "    Text = re.sub(\"[0-9\" \"]+\",\" \",Text)\n",
    "    Text = re.sub('[‘’“”…]', '', Text)\n",
    "    return Text\n",
    "\n",
    "clean = lambda x: clean_Text(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9634c026",
   "metadata": {},
   "outputs": [],
   "source": [
    "elon['Text'] = elon.Text.apply(clean)\n",
    "elon.Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab914bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "elon = [Text.strip() for Text in elon.Text]\n",
    "elon = [Text for Text in elon if Text]\n",
    "elon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e179964c",
   "metadata": {},
   "outputs": [],
   "source": [
    "elon_Text = ''.join(elon)\n",
    "len(elon_Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0ebc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(elon_Text[0:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f375a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "elon_tokens = word_tokenize(elon_Text)\n",
    "print(elon_tokens[0:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6b4394",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(elon_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de963601",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk  \n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4964e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "sw = stopwords.words('english')\n",
    "sw.append('the')\n",
    "stop_tokens = [word for word in elon_tokens if not word in sw]\n",
    "print(stop_tokens[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abba41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(stop_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b9edd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_words = [text.lower() for Text in stop_tokens]\n",
    "print(lower_words[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cb0e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spacy\n",
    "!python -m spacy downlaod en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d96c95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#english language model of spacy is nlp\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8790ca8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(''.join(lower_words))\n",
    "print(doc[0:1000])          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433105cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = [token.lemma_ for token in doc ]\n",
    "print(lemmas[0:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24adf13",
   "metadata": {},
   "source": [
    "FEATURE EXPANSION\n",
    "\n",
    "• USING COUNT VECTORIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5186199",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CounterVectorizer()\n",
    "eloncv = cv.fit_transform(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7441324",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cv.get_feature_names()[100:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422d8fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eloncv.toarray()[100:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3217c774",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eloncv.toarray().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2b154c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#COUNT VECTORIZER WITH NGRAMS\n",
    "cv_ngram_range = CountVectorizer(analyzer = 'word',ngram_range=(1,3),max_feature=100)\n",
    "box_matrix_ngram = cv_ngram_range.fit_transform(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6561d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cv_ngram_range.get_feature_names)\n",
    "print(bow_matrix_ngram.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628d70b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF VECTORIZER\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidfv_ngram_max_features = TfidfVectorizer(norm = '12',analyzer = 'word',ngram_range=(1,3),max_features=500)\n",
    "tf_idf_ngram = tfidfv_ngram_max_features.fit_transform(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b34b649",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tfidfv_ngram_max_features.get_feature_names())\n",
    "print(tfidf_matrix_ngram.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728c4973",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweets = ' '.join(lemmas)\n",
    "clean_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bafacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GENERATING WORLD CLOUD\n",
    "#define a function to plot word cloud\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_cloud(wordcloud):\n",
    "    plt.figure(figsize=(40,30))\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis('off')\n",
    "    \n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "STOPWORDS.add('pron')\n",
    "STOPWORDS.add('rt')\n",
    "STOPWORDS.add('yeah')\n",
    "wordcloud = WordCloud(width=3000,hieght=2000,backgroung_color = 'grey',max_words=50,color_map = 'set1',stopwords=STOPWORDS).generate(clean_tweets)\n",
    "plot_cloud(wordcloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef2d573",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NAMED ENTITY RECOGNIZER\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "one_block = clean_tweets\n",
    "doc_block = nlp(one_block)\n",
    "spacy.displacy.render(doc_block,style='ent',jupyter = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a20742",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in doc_block[500:600]:\n",
    "    print(token,token.pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28663daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FILTERING THE NOUNS AND VERBS\n",
    "noun_verbs = [token.Text for token in doc_block if token.pos_ in ('NOUN','VERB')]\n",
    "print(noun_verbs[500:600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534c2118",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counting the noun and verb token\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "x = cv.fit_transform(noun_verbs)\n",
    "sum_words = x.sum(axis=0)\n",
    "words_freq = [(word,sum_words[0,idx]) for word,idx in cv_vocabulary_.items()]\n",
    "words_freq = sorted(words_freq, key= lambda x: x[1] , reverse = True)\n",
    "wd_df = DataFrame(words_freq)\n",
    "wd_df.columns = ['word','count']\n",
    "wd_df[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfc914a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing\n",
    "wd_df[0:10].plot.bar(x = 'word',figsize=(12,8),title = 'Top 10 nouns and verbs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d567ead2",
   "metadata": {},
   "source": [
    "EMOTIONAL MINING - SENTIMENTAL ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7327cd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv(\"/Users/nihadnazar/Desktop/ASSIGNMENTS/DATASETS/Elon_musk.csv\",encoding=\"latin 1\")\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d1adb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.drop(['Unnamed: 0'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbef62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.rename({'Text': 'text'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f67edf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb1c82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re #regular_expression\n",
    "import string\n",
    "# Removing Punctuation\n",
    "\n",
    "def clean_text(text):\n",
    "    '''Make text lowercase, remove text in square brackets, remove punctuation and remove words containing numbers.'''\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    text = re.sub(\"[0-9\" \"]+\",\" \",text)\n",
    "    text = re.sub('[‘’“”…]', '', text)\n",
    "    return text\n",
    "\n",
    "clean = lambda x: clean_text(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e6f075",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['text'] = tweets.text.apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bcc172",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = [text.strip() for text in tweets.text]\n",
    "tweets = [text for text in tweets if text]\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9533fb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import tokenize\n",
    "sentences = tokenize.sent_tokenize(''.join(tweets))\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a81f31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_df = pd.DataFrame(tweets,columns=[sentence])\n",
    "sent_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a5b55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "affin =  pd.read_csv(\"/Users/nihadnazar/Desktop/ASSIGNMENTS/DATASETS/Elon_musk.csv\",encoding=\"latin 1\")\n",
    "affin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cf4d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "affinity_score = affin.set_index('word')['value'].to_dict()\n",
    "affinity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668004c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a3584a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_lexicon = affinity_score\n",
    "\n",
    "def calculate_sentiment(text:str=None):\n",
    "    sent_score=0\n",
    "    if text:\n",
    "        sentence = nlp(text)\n",
    "        for word in sentence:\n",
    "            sent_score+=sentiment_lexicon.get(word.lemma_,0)\n",
    "    return sent_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec8647f",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(''.join(lower_words))\n",
    "print(doc[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab3c1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#manual testing\n",
    "calculate_sentiment(text='great')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb3d38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating sentiment value for each sentence\n",
    "sent_df['sentiment_value'] = sent_df['sentence'].apply(calculate_sentiment)\n",
    "sent_df['sentiment_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1387cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_df.sort_values(by='sentiment_value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18db9360",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentiment of whole review\n",
    "sent_df['sentiment_value'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2431520",
   "metadata": {},
   "outputs": [],
   "source": [
    "#negative sentiment score of whole review\n",
    "sent_df[sent_df['sentiment_value']<=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0000de8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#positive sentiment score of whole review\n",
    "sent_df[sent_df['sentiment_value']>=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b7c4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding index column\n",
    "sent_df['index'] = range(0,len(sent_df))\n",
    "sent_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40aa0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the sentiment value for the whole review\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.distplot(sent_df['sentiment_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97ea3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the line plot for sentiment value for the whole review\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.lineplot(y='sentiment_value',x='index',data=sent_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402c0139",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bd3126",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
